<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="Ghislain Durif" />

<meta name="date" content="2024-02-12" />

<title>Introduction to RKeOps</title>

<script>// Pandoc 2.9 adds attributes on both header and div. We remove the former (to
// be compatible with the behavior of Pandoc < 2.8).
document.addEventListener('DOMContentLoaded', function(e) {
  var hs = document.querySelectorAll("div.section[class*='level'] > :first-child");
  var i, h, a;
  for (i = 0; i < hs.length; i++) {
    h = hs[i];
    if (!/^h[1-6]$/i.test(h.tagName)) continue;  // it should be a header h1-h6
    a = h.attributes;
    while (a.length > 0) h.removeAttribute(a[0].name);
  }
});
</script>

<style type="text/css">
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
span.underline{text-decoration: underline;}
div.column{display: inline-block; vertical-align: top; width: 50%;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
</style>



<style type="text/css">
code {
white-space: pre;
}
.sourceCode {
overflow: visible;
}
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
{ counter-reset: source-line 0; }
pre.numberSource code > span
{ position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
{ content: counter(source-line);
position: relative; left: -1em; text-align: right; vertical-align: baseline;
border: none; display: inline-block;
-webkit-touch-callout: none; -webkit-user-select: none;
-khtml-user-select: none; -moz-user-select: none;
-ms-user-select: none; user-select: none;
padding: 0 4px; width: 4em;
color: #aaaaaa;
}
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa; padding-left: 4px; }
div.sourceCode
{ }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } 
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.at { color: #7d9029; } 
code span.bn { color: #40a070; } 
code span.bu { color: #008000; } 
code span.cf { color: #007020; font-weight: bold; } 
code span.ch { color: #4070a0; } 
code span.cn { color: #880000; } 
code span.co { color: #60a0b0; font-style: italic; } 
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.do { color: #ba2121; font-style: italic; } 
code span.dt { color: #902000; } 
code span.dv { color: #40a070; } 
code span.er { color: #ff0000; font-weight: bold; } 
code span.ex { } 
code span.fl { color: #40a070; } 
code span.fu { color: #06287e; } 
code span.im { color: #008000; font-weight: bold; } 
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } 
code span.kw { color: #007020; font-weight: bold; } 
code span.op { color: #666666; } 
code span.ot { color: #007020; } 
code span.pp { color: #bc7a00; } 
code span.sc { color: #4070a0; } 
code span.ss { color: #bb6688; } 
code span.st { color: #4070a0; } 
code span.va { color: #19177c; } 
code span.vs { color: #4070a0; } 
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } 
</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    var j = 0;
    while (j < rules.length) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") {
        j++;
        continue;
      }
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') {
        j++;
        continue;
      }
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; } 
code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Introduction to RKeOps</h1>
<h4 class="author">Ghislain Durif</h4>
<h4 class="date">2024-02-12</h4>


<div id="TOC">
<ul>
<li><a href="#authors" id="toc-authors">Authors</a></li>
<li><a href="#citation" id="toc-citation">Citation</a></li>
<li><a href="#what-is-rkeops" id="toc-what-is-rkeops">What is
RKeOps?</a>
<ul>
<li><a href="#keops" id="toc-keops">KeOps</a></li>
<li><a href="#rkeops" id="toc-rkeops">RKeOps</a></li>
<li><a href="#why-using-rkeops" id="toc-why-using-rkeops">Why using
RKeOps?</a></li>
</ul></li>
<li><a href="#installing-and-using-rkeops" id="toc-installing-and-using-rkeops">Installing and using
RKeOps</a></li>
<li><a href="#examples-in-r" id="toc-examples-in-r">Examples in R</a>
<ul>
<li><a href="#example-in-r-with-lazytensors" id="toc-example-in-r-with-lazytensors">Example in R with
LazyTensors</a></li>
<li><a href="#example-in-r-with-generic-reductions" id="toc-example-in-r-with-generic-reductions">Example in R with generic
reductions</a></li>
</ul></li>
<li><a href="#cpu-and-gpu-computing" id="toc-cpu-and-gpu-computing">CPU
and GPU computing</a></li>
<li><a href="#matrix-reduction-and-kernel-operator" id="toc-matrix-reduction-and-kernel-operator">Matrix reduction and
kernel operator</a>
<ul>
<li><a href="#what-you-need-to-do" id="toc-what-you-need-to-do">What you
need to do</a></li>
<li><a href="#generic-kernel-function" id="toc-generic-kernel-function">Generic kernel function</a></li>
</ul></li>
<li><a href="#examplestutorialsbenchmarks" id="toc-examplestutorialsbenchmarks">Examples/Tutorials/Benchmarks</a>
<ul>
<li><a href="#using-rkeops" id="toc-using-rkeops">Using RKeOps</a></li>
<li><a href="#lazytensors" id="toc-lazytensors">LazyTensors</a></li>
<li><a href="#kernel-interpolation" id="toc-kernel-interpolation">Kernel
interpolation</a></li>
<li><a href="#benchmarks" id="toc-benchmarks">Benchmarks</a></li>
</ul></li>
</ul>
</div>

<ul>
<li>Documentation URL: <a href="https://www.kernel-operations.io/rkeops/" class="uri">https://www.kernel-operations.io/rkeops/</a></li>
<li>KeOps project URL: <a href="https://www.kernel-operations.io/" class="uri">https://www.kernel-operations.io/</a></li>
<li>Source: <a href="https://github.com/getkeops/keops" class="uri">https://github.com/getkeops/keops</a></li>
<li>Licence and Copyright: see <a href="https://github.com/getkeops/keops/blob/main/licence.txt" class="uri">https://github.com/getkeops/keops/blob/main/licence.txt</a></li>
</ul>
<div id="authors" class="section level1">
<h1>Authors</h1>
<p>Please contact us for any <strong>bug report</strong>,
<strong>question</strong> or <strong>feature request</strong> by filing
a report on our <a href="https://github.com/getkeops/keops/issues">GitHub issue
tracker</a>!</p>
<p><strong>Core library - KeOps, PyKeOps, KeOpsLab:</strong></p>
<ul>
<li><a href="https://imag.umontpellier.fr/~charlier/">Benjamin
Charlier</a>, from the University of Montpellier.</li>
<li><a href="https://www.jeanfeydy.com">Jean Feydy</a>, from Inria.</li>
<li><a href="http://helios.mi.parisdescartes.fr/~glaunes/">Joan Alexis
Glaunès</a>, from the University of Paris.</li>
</ul>
<p><strong>R bindings - RKeOps:</strong></p>
<ul>
<li>Amelie Vernay, from the University of Montpellier.</li>
<li>Chloe Serre-Combe, from the University of Montpellier.</li>
<li><a href="https://gdurif.perso.math.cnrs.fr/">Ghislain Durif</a>,
from CNRS.</li>
</ul>
<p><strong>Contributors:</strong></p>
<ul>
<li><a href="https://github.com/fradav">François-David Collin</a>, from
the University of Montpellier: Tensordot operation, CI setup.</li>
<li><a href="https://github.com/tanglef">Tanguy Lefort</a>, from the
University of Montpellier: conjugate gradient solver.</li>
<li><a href="https://github.com/mdiazmel">Mauricio Diaz</a>, from Inria
of Paris: CI setup.</li>
<li><a href="https://github.com/benoitmartin88">Benoît Martin</a>, from
the Aramis Inria team: multi-GPU support.</li>
<li><a href="https://www.fwilliams.info">Francis Williams</a>, from New
York University: maths operations.</li>
<li><a href="https://github.com/kshitij12345">Kshiteej Kalambarkar</a>,
from Quansight: maths operations.</li>
<li><a href="https://djsutherland.ml">D. J. Sutherland</a>, from the
TTI-Chicago: bug fix in the Python package.</li>
<li><a href="https://scholar.google.no/citations?user=ngT2GvMAAAAJ&amp;hl=en">David
Völgyes</a>, from the Norwegian Institute of Science and Technology: bug
fix in the formula parser.</li>
</ul>
<p>Beyond explicit code contributions, KeOps has grown out of numerous
discussions with applied mathematicians and machine learning experts. We
would especially like to thank <a href="https://atrouve.perso.math.cnrs.fr/">Alain Trouvé</a>, <a href="https://who.rocq.inria.fr/Stanley.Durrleman/">Stanley
Durrleman</a>, <a href="http://www.gpeyre.com/">Gabriel Peyré</a> and <a href="https://people.lu.usi.ch/bronstem/">Michael Bronstein</a> for
their valuable suggestions and financial support.</p>
<hr />
</div>
<div id="citation" class="section level1">
<h1>Citation</h1>
<p>If you use this code in a research paper, <strong>please
cite</strong> our <a href="https://jmlr.org/papers/v22/20-275.html">original
publication</a>:</p>
<blockquote>
<p>Charlier, B., Feydy, J., Glaunès, J. A., Collin, F.-D. &amp; Durif,
G. Kernel Operations on the GPU, with Autodiff, without Memory
Overflows. Journal of Machine Learning Research 22, 1–6 (2021).</p>
</blockquote>
<div class="sourceCode" id="cb1"><pre class="sourceCode tex"><code class="sourceCode latex"><span id="cb1-1"><a href="#cb1-1" tabindex="-1"></a>@article{JMLR:v22:20-275,</span>
<span id="cb1-2"><a href="#cb1-2" tabindex="-1"></a>  author  = {Benjamin Charlier and Jean Feydy and Joan Alexis Glaunès and François-David Collin and Ghislain Durif},</span>
<span id="cb1-3"><a href="#cb1-3" tabindex="-1"></a>  title   = {Kernel Operations on the GPU, with Autodiff, without Memory Overflows},</span>
<span id="cb1-4"><a href="#cb1-4" tabindex="-1"></a>  journal = {Journal of Machine Learning Research},</span>
<span id="cb1-5"><a href="#cb1-5" tabindex="-1"></a>  year    = {2021},</span>
<span id="cb1-6"><a href="#cb1-6" tabindex="-1"></a>  volume  = {22},</span>
<span id="cb1-7"><a href="#cb1-7" tabindex="-1"></a>  number  = {74},</span>
<span id="cb1-8"><a href="#cb1-8" tabindex="-1"></a>  pages   = {1-6},</span>
<span id="cb1-9"><a href="#cb1-9" tabindex="-1"></a>  url     = {https://jmlr.org/papers/v22/20-275.html}</span>
<span id="cb1-10"><a href="#cb1-10" tabindex="-1"></a>}</span></code></pre></div>
<p>For applications to <strong>geometric (deep) learning</strong>, you
may also consider our <a href="https://www.jeanfeydy.com/Papers/KeOps_NeurIPS_2020.pdf">NeurIPS
2020 paper</a>:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode tex"><code class="sourceCode latex"><span id="cb2-1"><a href="#cb2-1" tabindex="-1"></a>@article{feydy2020fast,</span>
<span id="cb2-2"><a href="#cb2-2" tabindex="-1"></a>    title={Fast geometric learning with symbolic matrices},</span>
<span id="cb2-3"><a href="#cb2-3" tabindex="-1"></a>    author={Feydy, Jean and Glaun{<span class="fu">\`</span>e}s, Joan and Charlier, Benjamin and Bronstein, Michael},</span>
<span id="cb2-4"><a href="#cb2-4" tabindex="-1"></a>    journal={Advances in Neural Information Processing Systems},</span>
<span id="cb2-5"><a href="#cb2-5" tabindex="-1"></a>    volume={33},</span>
<span id="cb2-6"><a href="#cb2-6" tabindex="-1"></a>    year={2020}</span>
<span id="cb2-7"><a href="#cb2-7" tabindex="-1"></a>}</span></code></pre></div>
<hr />
</div>
<div id="what-is-rkeops" class="section level1">
<h1>What is RKeOps?</h1>
<p>RKeOps is the R package interfacing the KeOps library.</p>
<div id="keops" class="section level2">
<h2>KeOps</h2>
<blockquote>
<p>Seamless Kernel Operations on GPU (or CPU), with auto-differentiation
and without memory overflows</p>
</blockquote>
<p>The KeOps library (<a href="http://www.kernel-operations.io" class="uri">http://www.kernel-operations.io</a>) provides routines to
compute generic reductions of large 2d arrays whose entries are given by
a mathematical formula. Using a C++/CUDA-based implementation with GPU
support, it combines a tiled reduction scheme with an automatic
differentiation engine. Relying on online map-reduce schemes, it is
perfectly suited to the scalable computation of kernel dot products and
the associated gradients, even when the full kernel matrix does not fit
into the GPU memory.</p>
<p>KeOps is all about breaking through this memory bottleneck and making
GPU power available for seamless standard mathematical routine
computations. As of 2019, this effort has been mostly restricted to the
operations needed to implement Convolutional Neural Networks: linear
algebra routines and convolutions on grids, images and volumes. KeOps
provides CPU and GPU support without the cost of developing a specific
CUDA implementation of your custom mathematical operators.</p>
<p>To ensure its versatility, KeOps can be used through Matlab, Python
(NumPy or PyTorch) and R back-ends.</p>
</div>
<div id="rkeops" class="section level2">
<h2>RKeOps</h2>
<p>RKeOps is a library that can<br><br></p>
<ul>
<li><p>Compute <strong>generic reduction</strong> (row-wise or
column-wise) of very large array/matrices, i.e. <span class="math display">\[\sum_{i=1}^M a_{ij} \ \ \ \ \text{or}\ \ \ \
\sum_{j=1}^N a_{ij}\]</span> for some matrix <span class="math inline">\(A = [a_{ij}]_{M \times N}\)</span> with <span class="math inline">\(M\)</span> rows and <span class="math inline">\(N\)</span> columns, whose entries <span class="math inline">\(a_{ij}\)</span> can be defined with basic math
formulae or matrix operators.<br><br></p></li>
<li><p>Compute <strong>kernel dot products</strong>, i.e. <span class="math display">\[\sum_{i=1}^M K(\mathbf x_i, \mathbf y_j)\ \ \ \
\text{or}\ \ \ \ \sum_{j=1}^N K(\mathbf x_i, \mathbf y_j)\]</span> for a
kernel function <span class="math inline">\(K\)</span> and some vectors
<span class="math inline">\(\mathbf x_i\)</span>, <span class="math inline">\(\mathbf y_j\in \mathbb{R}^D\)</span> that are
generally rows of some data matrices <span class="math inline">\(\mathbf
X = [x_{ik}]_{M \times D}\)</span> and <span class="math inline">\(\mathbf Y = [y_{jk}]_{N \times D}\)</span>
respectively.<br><br></p></li>
<li><p>Compute the <strong>associated
gradients</strong><br><br></p></li>
</ul>
<blockquote>
<p><strong><em>Applications</em></strong>: RKeOps can be used to
implement a wide range of problems encountered in <strong><em>machine
learning</em></strong>, <strong><em>statistics</em></strong> and more:
such as <span class="math inline">\(k\)</span>-nearest neighbor
classification, <span class="math inline">\(k\)</span>-means clustering,
Gaussian-kernel-based problems (e.g. linear system with Ridge
regularization), etc.</p>
</blockquote>
</div>
<div id="why-using-rkeops" class="section level2">
<h2>Why using RKeOps?</h2>
<p>RKeOps provides<br></p>
<ul>
<li><p>a <strong>symbolic computation</strong> framework to seamlessly
process very large arrays writing <strong>R-base-matrix-like
operations</strong> based on lazy evaluations.<br></p></li>
<li><p>an API to create <strong>user-defined operators</strong> based on
generic mathematical formulae, that can be applied to data matrices such
as <span class="math inline">\(\mathbf X = [x_{ik}]_{M \times
D}\)</span> and <span class="math inline">\(\mathbf Y = [y_{jk}]_{N
\times D}\)</span>.<br></p></li>
<li><p>fast computation on <strong>GPU</strong> without memory overflow,
especially to process <strong>very large dimensions</strong> <span class="math inline">\(M\)</span> and <span class="math inline">\(N\)</span> (e.g. <span class="math inline">\(\approx 10^4\)</span> or <span class="math inline">\(10^6\)</span>) over indexes <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span>.<br></p></li>
<li><p>automatic differentiation and <strong>gradient
computations</strong> for user-defined operators.<br></p></li>
</ul>
<hr />
</div>
</div>
<div id="installing-and-using-rkeops" class="section level1">
<h1>Installing and using RKeOps</h1>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" tabindex="-1"></a><span class="co"># install rkeops</span></span>
<span id="cb3-2"><a href="#cb3-2" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;rkeops&quot;</span>)</span>
<span id="cb3-3"><a href="#cb3-3" tabindex="-1"></a><span class="co"># load rkeops</span></span>
<span id="cb3-4"><a href="#cb3-4" tabindex="-1"></a><span class="fu">library</span>(rkeops)</span>
<span id="cb3-5"><a href="#cb3-5" tabindex="-1"></a><span class="co"># create a dedicated Python environment with reticulate (to be done only once)</span></span>
<span id="cb3-6"><a href="#cb3-6" tabindex="-1"></a>reticulate<span class="sc">::</span><span class="fu">virtualenv_create</span>(<span class="st">&quot;rkeops&quot;</span>)</span>
<span id="cb3-7"><a href="#cb3-7" tabindex="-1"></a><span class="co"># activate the dedicated Python environment</span></span>
<span id="cb3-8"><a href="#cb3-8" tabindex="-1"></a>reticulate<span class="sc">::</span><span class="fu">use_virtualenv</span>(<span class="at">virtualenv =</span> <span class="st">&quot;rkeops&quot;</span>, <span class="at">required =</span> <span class="cn">TRUE</span>)</span>
<span id="cb3-9"><a href="#cb3-9" tabindex="-1"></a><span class="co"># install rkeops requirements (to be done only once)</span></span>
<span id="cb3-10"><a href="#cb3-10" tabindex="-1"></a><span class="fu">install_rkeops</span>()</span></code></pre></div>
<p>For more details, see the specific <strong>“Using RKeOps” <a href="https://www.kernel-operations.io/rkeops/articles/using_rkeops.html">article</a></strong>
or the corresponding vignette:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" tabindex="-1"></a><span class="fu">vignette</span>(<span class="st">&quot;using_rkeops&quot;</span>, <span class="at">package =</span> <span class="st">&quot;rkeops&quot;</span>)</span></code></pre></div>
<hr />
</div>
<div id="examples-in-r" class="section level1">
<h1>Examples in R</h1>
<div id="example-in-r-with-lazytensors" class="section level2">
<h2>Example in R with LazyTensors</h2>
<p>Lazy evaluation allows to write intermediate computations as symbolic
operations that are not directly evaluated. The real evaluation is only
made on final computation.</p>
<p>To do so, you can use <code>LazyTensors</code>. These are objects
wrapped around R matrices or vectors used to create symbolic formulas
for the <code>KeOps</code> reduction operations. A typical use case is
the following:</p>
<p>Let us say that we want to compute (for all <span class="math inline">\(j=1,\dots,N\)</span>):</p>
<p><span class="math display">\[
a_j = \sum_{i=1}^{M} \exp\left(-\frac{\Vert \mathbf x_i - \mathbf
y_j\Vert^2}{s^2}\right)
\]</span></p>
<p>with</p>
<ul>
<li><p>parameter: <span class="math inline">\(s \in\mathbb
R\)</span><br></p></li>
<li><p><span class="math inline">\(i\)</span>-indexed variables <span class="math inline">\(\mathbf X = [\mathbf x_i]_{i=1,...,M} \in\mathbb
R^{M\times 3}\)</span><br></p></li>
<li><p><span class="math inline">\(j\)</span>-indexed variables <span class="math inline">\(\mathbf Y = [\mathbf y_j]_{j=1,...,N} \in\mathbb
R^{N\times 3}\)</span><br><br></p></li>
</ul>
<p>The associated code would be:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" tabindex="-1"></a><span class="co"># to run computation on CPU (default mode)</span></span>
<span id="cb5-2"><a href="#cb5-2" tabindex="-1"></a><span class="fu">rkeops_use_cpu</span>()</span>
<span id="cb5-3"><a href="#cb5-3" tabindex="-1"></a><span class="co"># OR</span></span>
<span id="cb5-4"><a href="#cb5-4" tabindex="-1"></a><span class="co"># to run computations on GPU (to be used only if relevant)</span></span>
<span id="cb5-5"><a href="#cb5-5" tabindex="-1"></a><span class="fu">rkeops_use_gpu</span>()</span>
<span id="cb5-6"><a href="#cb5-6" tabindex="-1"></a></span>
<span id="cb5-7"><a href="#cb5-7" tabindex="-1"></a><span class="co"># Data</span></span>
<span id="cb5-8"><a href="#cb5-8" tabindex="-1"></a>M <span class="ot">&lt;-</span> <span class="dv">10000</span></span>
<span id="cb5-9"><a href="#cb5-9" tabindex="-1"></a>N <span class="ot">&lt;-</span> <span class="dv">15000</span></span>
<span id="cb5-10"><a href="#cb5-10" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">runif</span>(N <span class="sc">*</span> <span class="dv">3</span>), <span class="at">nrow =</span> M, <span class="at">ncol =</span> <span class="dv">3</span>) <span class="co"># arbitrary R matrix representing </span></span>
<span id="cb5-11"><a href="#cb5-11" tabindex="-1"></a>                                              <span class="co"># 10000 data points in R^3</span></span>
<span id="cb5-12"><a href="#cb5-12" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">runif</span>(M <span class="sc">*</span> <span class="dv">3</span>), <span class="at">nrow =</span> N, <span class="at">ncol =</span> <span class="dv">3</span>) <span class="co"># arbitrary R matrix representing </span></span>
<span id="cb5-13"><a href="#cb5-13" tabindex="-1"></a>                                              <span class="co"># 15000 data points in R^3</span></span>
<span id="cb5-14"><a href="#cb5-14" tabindex="-1"></a>s <span class="ot">&lt;-</span> <span class="fl">0.1</span>                                      <span class="co"># scale parameter</span></span>
<span id="cb5-15"><a href="#cb5-15" tabindex="-1"></a></span>
<span id="cb5-16"><a href="#cb5-16" tabindex="-1"></a><span class="co"># Turn our Tensors into KeOps symbolic variables:</span></span>
<span id="cb5-17"><a href="#cb5-17" tabindex="-1"></a>x_i <span class="ot">&lt;-</span> <span class="fu">LazyTensor</span>(x, <span class="st">&quot;i&quot;</span>)     <span class="co"># symbolic object representing an arbitrary row of x, </span></span>
<span id="cb5-18"><a href="#cb5-18" tabindex="-1"></a>                              <span class="co"># indexed by the letter &quot;i&quot;</span></span>
<span id="cb5-19"><a href="#cb5-19" tabindex="-1"></a>y_j <span class="ot">&lt;-</span> <span class="fu">LazyTensor</span>(y, <span class="st">&quot;j&quot;</span>)     <span class="co"># symbolic object representing an arbitrary row of y, </span></span>
<span id="cb5-20"><a href="#cb5-20" tabindex="-1"></a>                              <span class="co"># indexed by the letter &quot;j&quot;</span></span>
<span id="cb5-21"><a href="#cb5-21" tabindex="-1"></a></span>
<span id="cb5-22"><a href="#cb5-22" tabindex="-1"></a><span class="co"># Perform large-scale computations, without memory overflows:</span></span>
<span id="cb5-23"><a href="#cb5-23" tabindex="-1"></a>D_ij <span class="ot">&lt;-</span> <span class="fu">sum</span>((x_i <span class="sc">-</span> y_j)<span class="sc">^</span><span class="dv">2</span>)    <span class="co"># symbolic matrix of pairwise squared distances, </span></span>
<span id="cb5-24"><a href="#cb5-24" tabindex="-1"></a>                              <span class="co"># with 10000 rows and 15000 columns</span></span>
<span id="cb5-25"><a href="#cb5-25" tabindex="-1"></a></span>
<span id="cb5-26"><a href="#cb5-26" tabindex="-1"></a>K_ij <span class="ot">&lt;-</span> <span class="fu">exp</span>(<span class="sc">-</span> D_ij <span class="sc">/</span> s<span class="sc">^</span><span class="dv">2</span>)     <span class="co"># symbolic matrix, 10000 rows and 15000 columns</span></span>
<span id="cb5-27"><a href="#cb5-27" tabindex="-1"></a></span>
<span id="cb5-28"><a href="#cb5-28" tabindex="-1"></a><span class="co"># D_ij and K_ij are only symbolic at that point, no computation is done</span></span>
<span id="cb5-29"><a href="#cb5-29" tabindex="-1"></a></span>
<span id="cb5-30"><a href="#cb5-30" tabindex="-1"></a><span class="co"># Computing the result without storing D_ij and K_ij:</span></span>
<span id="cb5-31"><a href="#cb5-31" tabindex="-1"></a>a_j <span class="ot">&lt;-</span> <span class="fu">sum</span>(K_ij, <span class="at">index =</span> <span class="st">&quot;i&quot;</span>) <span class="co"># actual R matrix (in fact a row vector of </span></span>
<span id="cb5-32"><a href="#cb5-32" tabindex="-1"></a>                              <span class="co"># length 15000 here)</span></span>
<span id="cb5-33"><a href="#cb5-33" tabindex="-1"></a>                              <span class="co"># containing the column sums of K_ij</span></span>
<span id="cb5-34"><a href="#cb5-34" tabindex="-1"></a>                              <span class="co"># (i.e. the sums over the &quot;i&quot; index, for each </span></span>
<span id="cb5-35"><a href="#cb5-35" tabindex="-1"></a>                              <span class="co"># &quot;j&quot; index)</span></span></code></pre></div>
<p><strong>More in the dedicated “RKeOps LazyTensor” <a href="https://www.kernel-operations.io/rkeops/articles/LazyTensor_rkeops.html">article</a></strong>
or in the corresponding vignette:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb6-1"><a href="#cb6-1" tabindex="-1"></a><span class="fu">vignette</span>(<span class="st">&quot;LazyTensor_rkeops&quot;</span>, <span class="at">package =</span> <span class="st">&quot;rkeops&quot;</span>)</span></code></pre></div>
</div>
<div id="example-in-r-with-generic-reductions" class="section level2">
<h2>Example in R with generic reductions</h2>
<p>We want to implement with RKeOps the following mathematical formula
<span class="math display">\[\sum_{j=1}^{N} \exp\Big(-\sigma || \mathbf
x_i - \mathbf y_j ||_2^{\,2}\Big)\,\mathbf b_j\]</span> with</p>
<ul>
<li><p>parameter: <span class="math inline">\(\sigma\in\mathbb
R\)</span><br></p></li>
<li><p><span class="math inline">\(i\)</span>-indexed variables <span class="math inline">\(\mathbf X = [\mathbf x_i]_{i=1,...,M} \in\mathbb
R^{M\times 3}\)</span><br></p></li>
<li><p><span class="math inline">\(j\)</span>-indexed variables <span class="math inline">\(\mathbf Y = [\mathbf y_j]_{j=1,...,N} \in\mathbb
R^{N\times 3}\)</span> and <span class="math inline">\(\mathbf B =
[\mathbf b_j]_{j=1,...,N} \in\mathbb R^{N\times
6}\)</span><br><br></p></li>
</ul>
<p>In R, we can define the corresponding KeOps formula as a
<strong>simple text string</strong>:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" tabindex="-1"></a>formula <span class="ot">=</span> <span class="st">&quot;Sum_Reduction(Exp(-s * SqNorm2(x - y)) * b, 0)&quot;</span></span></code></pre></div>
<ul>
<li><code>SqNorm2</code> = squared <span class="math inline">\(\ell_2\)</span> norm</li>
<li><code>Exp</code> = exponential</li>
<li><code>Sum_reduction(..., 0)</code> = sum reduction over the
dimension 0 i.e. sum on the <span class="math inline">\(j\)</span>’s (1
to sum over the <span class="math inline">\(i\)</span>’s)<br></li>
</ul>
<p>and the corresponding arguments of the formula, i.e. parameters or
variables indexed by <span class="math inline">\(i\)</span> or <span class="math inline">\(j\)</span> with their corresponding inner
dimensions:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb8-1"><a href="#cb8-1" tabindex="-1"></a>args <span class="ot">=</span> <span class="fu">c</span>(<span class="st">&quot;x = Vi(3)&quot;</span>,      <span class="co"># vector indexed by i (of dim 3)</span></span>
<span id="cb8-2"><a href="#cb8-2" tabindex="-1"></a>         <span class="st">&quot;y = Vj(3)&quot;</span>,      <span class="co"># vector indexed by j (of dim 3)</span></span>
<span id="cb8-3"><a href="#cb8-3" tabindex="-1"></a>         <span class="st">&quot;b = Vj(6)&quot;</span>,      <span class="co"># vector indexed by j (of dim 6)</span></span>
<span id="cb8-4"><a href="#cb8-4" tabindex="-1"></a>         <span class="st">&quot;s = Pm(1)&quot;</span>)      <span class="co"># parameter (scalar) </span></span></code></pre></div>
<p>Then we just compile the corresponding operator and apply it to some
data</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" tabindex="-1"></a><span class="co"># compilation</span></span>
<span id="cb9-2"><a href="#cb9-2" tabindex="-1"></a>op <span class="ot">&lt;-</span> <span class="fu">keops_kernel</span>(formula, args)</span>
<span id="cb9-3"><a href="#cb9-3" tabindex="-1"></a><span class="co"># data and parameter values</span></span>
<span id="cb9-4"><a href="#cb9-4" tabindex="-1"></a>nx <span class="ot">&lt;-</span> <span class="dv">100</span></span>
<span id="cb9-5"><a href="#cb9-5" tabindex="-1"></a>ny <span class="ot">&lt;-</span> <span class="dv">150</span></span>
<span id="cb9-6"><a href="#cb9-6" tabindex="-1"></a>X <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">runif</span>(nx<span class="sc">*</span><span class="dv">3</span>), <span class="at">nrow=</span>nx)   <span class="co"># matrix 100 x 3</span></span>
<span id="cb9-7"><a href="#cb9-7" tabindex="-1"></a>Y <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">runif</span>(ny<span class="sc">*</span><span class="dv">3</span>), <span class="at">nrow=</span>ny)   <span class="co"># matrix 150 x 3</span></span>
<span id="cb9-8"><a href="#cb9-8" tabindex="-1"></a>B <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">runif</span>(ny<span class="sc">*</span><span class="dv">6</span>), <span class="at">nrow=</span>ny)   <span class="co"># matrix 150 x 6</span></span>
<span id="cb9-9"><a href="#cb9-9" tabindex="-1"></a>s <span class="ot">&lt;-</span> <span class="fl">0.2</span></span>
<span id="cb9-10"><a href="#cb9-10" tabindex="-1"></a><span class="co"># computation (order of the input arguments should be similar to `args`)</span></span>
<span id="cb9-11"><a href="#cb9-11" tabindex="-1"></a>res <span class="ot">&lt;-</span> <span class="fu">op</span>(<span class="fu">list</span>(X, Y, B, s))</span></code></pre></div>
<hr />
</div>
</div>
<div id="cpu-and-gpu-computing" class="section level1">
<h1>CPU and GPU computing</h1>
<p>Based on your LazyTensor-based operations or formulae, RKeOps
compiles on the fly operators that can be used to run the corresponding
computations on CPU or GPU, it uses a tiling scheme to decompose the
data and avoid (i) useless and costly memory transfers between host and
GPU (performance gain) and (ii) memory overflow.</p>
<blockquote>
<p><strong>Note:</strong> You can use the same code (i.e. define the
same operators) for CPU or GPU computing. The only difference will be
the compiler used for the compilation of your operators (upon the
availability of CUDA on your system).</p>
</blockquote>
<p>To use CPU computing mode, you can call <code>rkeops_use_cpu()</code>
(with an optional argument <code>ncore</code> specifying the number of
cores used to run parallel computations).</p>
<p>To use GPU computing mode, you can call <code>rkeops_use_gpu()</code>
(with an optional argument <code>device</code> to choose a specific GPU
id to run computations).</p>
<hr />
</div>
<div id="matrix-reduction-and-kernel-operator" class="section level1">
<h1>Matrix reduction and kernel operator</h1>
<p>The general framework of RKeOps (and KeOps) is to provide fast and
scalable matrix operations on GPU, in particular kernel-based
computations of the form <span class="math display">\[\underset{i=1,...,M}{\text{reduction}}\
G(\boldsymbol{\sigma}, \mathbf x_i, \mathbf y_j) \ \ \ \ \text{or}\ \ \
\ \underset{j=1,...,N}{\text{reduction}}\ G(\boldsymbol{\sigma}, \mathbf
x_i, \mathbf y_j)\]</span> where<br></p>
<ul>
<li><p><span class="math inline">\(\boldsymbol{\sigma}\in\mathbb
R^L\)</span> is a vector of parameters<br></p></li>
<li><p><span class="math inline">\(\mathbf x_i\in \mathbb{R}^D\)</span>
and <span class="math inline">\(\mathbf y_j\in
\mathbb{R}^{D&#39;}\)</span> are two vectors of data (potentially with
different dimensions)<br></p></li>
<li><p><span class="math inline">\(G: \mathbb R^L \times \mathbb R^D
\times \mathbb R^{D&#39;} \to \mathbb R\)</span> is a function of the
data and the parameters, that can be expressed through a composition of
generic operators<br></p></li>
<li><p><span class="math inline">\(\text{reduction}\)</span> is a
generic reduction operation over the index <span class="math inline">\(i\)</span> or <span class="math inline">\(j\)</span> (e.g. sum)<br><br></p></li>
</ul>
<p>RKeOps creates (and compiles on the fly) an operator implementing
your formula. You can apply it to your data, or compute its gradient
regarding some data points.<br><br></p>
<blockquote>
<p><strong><em>Note:</em></strong> You can use a wide range of reduction
such as <code>sum</code>, <code>min</code>, <code>argmin</code>,
<code>max</code>, <code>argmax</code>, etc.</p>
</blockquote>
<div id="what-you-need-to-do" class="section level2">
<h2>What you need to do</h2>
<p>To use RKeOps you only need to express your computations as a formula
with the previous form.<br><br></p>
<p>RKeOps allows to use a wide range of mathematical functions to define
your operators (see <a href="https://www.kernel-operations.io/keops/api/math-operations.html" class="uri">https://www.kernel-operations.io/keops/api/math-operations.html</a>).<br><br></p>
<p>You can use two type of input matrices with RKeOps:<br></p>
<ul>
<li><p>ones whose rows (or columns) are indexed by <span class="math inline">\(i=1,...,M\)</span> such as <span class="math inline">\(\mathbf X = [x_{ik}]_{M \times
D}\)</span><br></p></li>
<li><p>others whose rows (or columns) are indexed by <span class="math inline">\(j=1,...,N\)</span> such as <span class="math inline">\(\mathbf Y = [y_{ik&#39;}]_{N \times
D&#39;}\)</span><br><br></p></li>
</ul>
<p>More details about input matrices (size, storage order) are given in
the <strong>“Using RKeOps” <a href="https://www.kernel-operations.io/rkeops/articles/using_rkeops.html">article</a></strong>
or the corresponding vignette::</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" tabindex="-1"></a><span class="fu">vignette</span>(<span class="st">&quot;using_rkeops&quot;</span>, <span class="at">package =</span> <span class="st">&quot;rkeops&quot;</span>)</span></code></pre></div>
</div>
<div id="generic-kernel-function" class="section level2">
<h2>Generic kernel function</h2>
<p>With RKeOps, you can define kernel functions <span class="math inline">\(K: \mathbb R^D \times \mathbb R^D \to \mathbb
R\)</span> such as, for some vectors <span class="math inline">\(\mathbf
x_i\)</span>, <span class="math inline">\(\mathbf y_j\in
\mathbb{R}^D\)</span><br></p>
<ul>
<li><p>the linear kernel (standard scalar product) <span class="math inline">\(K(\mathbf x_i, \mathbf y_j) = \big\langle \mathbf
x_i \, , \, \mathbf y_j \big\rangle\)</span> <br></p></li>
<li><p>the Gaussian kernel <span class="math inline">\(K(\mathbf x_i,
\mathbf y_j) = \exp\left(-\frac{1}{2\sigma^2} \Vert \mathbf x_i -
\mathbf y_j \Vert_2^{\,2}\right)\)</span> with <span class="math inline">\(\sigma&gt;0\)</span> <br></p></li>
<li><p>and more…<br><br></p></li>
</ul>
<p>Then you can compute reductions based on such functions, especially
when the <span class="math inline">\(M \times N\)</span> matrix <span class="math inline">\(\mathbf K = [K(\mathbf x_i, \mathbf y_j)]\)</span>
is too large to fit into memory, such as<br></p>
<ul>
<li><p>Kernel reduction: <span class="math display">\[\sum_{i=1}^M
K(\mathbf x_i, \mathbf y_j)\ \ \ \ \text{or}\ \ \ \ \sum_{j=1}^N
K(\mathbf x_i, \mathbf y_j)\]</span></p></li>
<li><p>Convolution-like operations: <span class="math display">\[\sum_{i=1}^M K(\mathbf x_i, \mathbf
y_j)\boldsymbol\beta_j\ \ \ \ \text{or}\ \ \ \ \sum_{j=1}^N K(\mathbf
x_i, \mathbf y_j)\boldsymbol\beta_j\]</span> for some vectors <span class="math inline">\((\boldsymbol\beta_j)_{j=1,...,N} \in \mathbb
R^{N\times D}\)</span><br><br></p></li>
<li><p>More complex operations: <span class="math display">\[\sum_{i=1}^{M}\, K_1(\mathbf x_i, \mathbf y_j)\,
K_2(\mathbf u_i, \mathbf v_j)\,\langle \boldsymbol\alpha_i\,
,\,\boldsymbol\beta_j\rangle \ \ \ \ \text{or}\ \ \ \ \sum_{j=1}^{N}\,
K_1(\mathbf x_i, \mathbf y_j)\, K_2(\mathbf u_i, \mathbf v_j)\,\langle
\boldsymbol\alpha_i\, ,\,\boldsymbol\beta_j\rangle\]</span> for some
kernels <span class="math inline">\(K_1\)</span> and <span class="math inline">\(K_2\)</span>, and some <span class="math inline">\(D\)</span>-vectors <span class="math inline">\((\mathbf x_i)_{i=1,...,M}, (\mathbf
u_i)_{i=1,...,M}, (\boldsymbol\alpha_i)_{i=1,...,M} \in \mathbb
R^{M\times D}\)</span> and <span class="math inline">\((\mathbf
y_j)_{j=1,...,N}, (\mathbf v_j)_{j=1,...,N},
(\boldsymbol\beta_j)_{j=1,...,N} \in \mathbb R^{N\times
D}\)</span>.</p></li>
</ul>
</div>
</div>
<div id="examplestutorialsbenchmarks" class="section level1">
<h1>Examples/Tutorials/Benchmarks</h1>
<div id="using-rkeops" class="section level2">
<h2>Using RKeOps</h2>
<p>See this <a href="https://www.kernel-operations.io/rkeops/articles/using_rkeops.html">article</a>
or the corresponding vignette:</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" tabindex="-1"></a><span class="fu">vignette</span>(<span class="st">&quot;using_rkeops&quot;</span>, <span class="at">package =</span> <span class="st">&quot;rkeops&quot;</span>)</span></code></pre></div>
</div>
<div id="lazytensors" class="section level2">
<h2>LazyTensors</h2>
<p>See this <a href="https://www.kernel-operations.io/rkeops/articles/LazyTensor_rkeops.html">article</a>
or the corresponding vignette:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" tabindex="-1"></a><span class="fu">vignette</span>(<span class="st">&quot;LazyTensor_rkeops&quot;</span>, <span class="at">package =</span> <span class="st">&quot;rkeops&quot;</span>)</span></code></pre></div>
</div>
<div id="kernel-interpolation" class="section level2">
<h2>Kernel interpolation</h2>
<p>See this <a href="https://www.kernel-operations.io/rkeops/articles/Kernel_Interpolation_rkeops.html">article</a>
or the corresponding vignette:</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" tabindex="-1"></a><span class="fu">vignette</span>(<span class="st">&quot;kernel_interpolation_rkeops&quot;</span>, <span class="at">package =</span> <span class="st">&quot;rkeops&quot;</span>)</span></code></pre></div>
</div>
<div id="benchmarks" class="section level2">
<h2>Benchmarks</h2>
<p>See the corresponding directory <a href="https://github.com/getkeops/keops/tree/main/rkeops/benchmarks"><code>rkeops/benchmarks</code></a>
in the project source repository.</p>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
